---
sort: 8
---

# ëª¨ë¸ ê²½ëŸ‰í™” (MobileNet)

*'20ë…„ë„ ì´ˆê³ ì•• GIS/Tr. ì§„ë‹¨ ëª¨ë¸ ê°œë°œ ì‹œ ì ìš©í•œ ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²•ì¸ MobileNetì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.*



  ìˆ˜ë°± ê°œì˜ ë””ë°”ì´ìŠ¤ê°€ ì—°ê²°ëœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì—ì„œ ì´ˆê³ ì•• GIS/Tr. ì œí’ˆì„ íƒ€ê²Ÿìœ¼ë¡œ í•˜ëŠ” ì§„ë‹¨ ëª¨ë¸ì„ ë§Œë“œëŠ” ì¤‘ ì‚½ì§ˆí–ˆë˜ ê²½í—˜ë‹´ì…ë‹ˆë‹¤.ğŸ˜±

  ì‹¤ì‹œê°„ ì§„ë‹¨ì„ í•´ì•¼í•˜ëŠ” ë§Œí¼ ì§„ë‹¨ ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì— ìƒì£¼í•´ì•¼ í•˜ë©°, ì œí’ˆë§ˆë‹¤ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ëª¨ë¸ í•˜ë‚˜ì˜ í¬ê¸°ë¥¼ ìµœëŒ€í•œ ì¤„ì´ëŠ” ì‘ì—…ì„ í•´ì•¼ í–ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ë¹ ë¥¸ ì¶”ë¡  ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ì„œë¼ë„ ëª¨ë¸ ê²½ëŸ‰í™”ëŠ” í•„ìˆ˜ì˜€ìŠµë‹ˆë‹¤. ëª¨ë¸ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê°€ì¥ ì‰¬ìš´ ë°©ë²•ì€ `1. ë ˆì´ì–´ ìˆ˜ ì¤„ì´ê¸°`, `2. Weight size ì¤„ì´ê¸°` ì´ì—ˆìŠµë‹ˆë‹¤. ê°œë°œ ì¤‘ ì‚¬ìš©í•œ ë°ì´í„°ëŠ” í•œ ëª¨ë¸ ë‹¹ ì•½ 500ì¥ ë¯¸ë§Œì…ë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê¸°ì—ëŠ” í„±ì—†ì´ ë¶€ì¡±í•œ ìˆ˜ ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ë°ì´í„°ê°€ ì ì€ ë•ë¶„ì— 1, 2ë²ˆ ë°©ë²•ì„ í†µí•´ ëª¨ë¸ì„ ì‘ê²Œ ë§Œë“¤ì–´ë„ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ëŠ” íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì‘ì€ ëª¨ë¸ì´ê¸°ì— ì ì€ ë°ì´í„°ë¡œ ì¶©ë¶„íˆ í•™ìŠµ ì‹œí‚¬ ìˆ˜ ìˆì—ˆê¸° ë•Œë¬¸ì´ì£ ! 

  ê·¸ëŸ¬ë‚˜ ì‹¤ì œ ì œí’ˆì— ë„£ê¸°ì—ëŠ” ì•„ì§ë„ ë¬´ê±°ìš´ ëª¨ë¸ì´ì—ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ì ì¸ CNN êµ¬ì¡°ì—ì„œ ë ˆì´ì–´ íŠœë‹ì„ í†µí•´ ëª¨ë¸ì„ ìµœëŒ€í•œ ì‘ê²Œ ë§Œë“  í›„ ì´ë³´ë‹¤ ë” ì‘ê²Œ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” `3. ê²½ëŸ‰í™” ê¸°ë²•`ì„ ì ìš©í•  ìˆ˜ ë°–ì— ì—†ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ **ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ CNNì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë‚˜ì˜¨ ê²½ëŸ‰í™” ê¸°ë²•ì¸ `MobileNet` ê¸°ë²•ì„ ì‚¬ìš©**í–ˆìŠµë‹ˆë‹¤. 



## ëª©ì°¨

- [ëª¨ë¸ ê²½ëŸ‰í™” (MobileNet)](#ëª¨ë¸-ê²½ëŸ‰í™”-mobilenet)
  - [ëª©ì°¨](#ëª©ì°¨)
  - [1. ë°°ê²½](#1-ë°°ê²½)
    - [ë¶€ë¶„ë°©ì „ ì´ë€](#ë¶€ë¶„ë°©ì „-ì´ë€)
    - [ë¶€ë¶„ë°©ì „ ì§„ë‹¨](#ë¶€ë¶„ë°©ì „-ì§„ë‹¨)
  - [2. ê¸°ì¡´ ëª¨ë¸ êµ¬ì¡°](#2-ê¸°ì¡´-ëª¨ë¸-êµ¬ì¡°)
    - [ì„±ëŠ¥ ë° í¬ê¸°](#ì„±ëŠ¥-ë°-í¬ê¸°)
  - [3. ê²½ëŸ‰í™” ë°©ë²•](#3-ê²½ëŸ‰í™”-ë°©ë²•)
    - [3.1. ë„¤íŠ¸ì›Œí¬ ê²½ëŸ‰í™”ì˜ ì¢…ë¥˜](#31-ë„¤íŠ¸ì›Œí¬-ê²½ëŸ‰í™”ì˜-ì¢…ë¥˜)
      - [ì™œ MobileNet?](#ì™œ-mobilenet)
    - [3.2. MobileNet](#32-mobilenet)
      - [3.2.1. MobileNet V1](#321-mobilenet-v1)
      - [3.2.2. MobileNet V2](#322-mobilenet-v2)
    - [3.3. ê²½ëŸ‰í™” ëª¨ë¸](#33-ê²½ëŸ‰í™”-ëª¨ë¸)
    - [ì„±ëŠ¥ ë° í¬ê¸°](#ì„±ëŠ¥-ë°-í¬ê¸°-1)



## 1. ë°°ê²½

### ë¶€ë¶„ë°©ì „ ì´ë€

   `ë¶€ë¶„ë°©ì „`(Partial Discharge: PD)ì´ë€ ë¶€ë¶„ì ìœ¼ë¡œ ì¼ì–´ë‚˜ëŠ” ë°©ì „ í˜„ìƒì´ë‹¤. ì ˆì—°ì²´ì— ì´ìƒì´ ìƒê²¨ ê³ ì „ì••ì´ ì ìš©ë˜ì—ˆì„ ë•Œ ë¶€ë¶„ì ìœ¼ë¡œ ì ˆì—°ì²´ì™€ ì „ë„ì²´ ì‚¬ì´ê°€ ì „ê¸°ì ìœ¼ë¡œ ì´ì–´ì§€ëŠ” í˜„ìƒì„ ë§í•œë‹¤. ë³´í†µ ë¶€ë¶„ë°©ì „ í˜„ìƒì€ ì „ê¸°ì  ìŠ¤íŠ¸ë ˆìŠ¤ì˜ ì§‘ì¤‘ìœ¼ë¡œ ì¸í•´ ë°œìƒí•œë‹¤. ì ˆì—°ì²´ì˜ ìˆ˜ëª…ì„ ë‹¨ì¶• ì‹œí‚¤ë©°, ì´ë¥¼ í†µí•´ **ì ˆì—°ì²´ì˜ ì ˆì—°ì—´í™”ë‚˜ ì ˆì—°íŒŒê´´ë¥¼ ì¡°ê¸°ì— ì¸¡ì •**í•  ìˆ˜ ìˆë‹¤. 



> â—ï¸**ì „ë ¥ê¸°ê¸°ì˜ ì ˆì—°ì²´ ìƒíƒœë¥¼ ì§„ë‹¨í•  ìˆ˜ ìˆëŠ” ì¤‘ìš”í•œ ì§€í‘œ**



### ë¶€ë¶„ë°©ì „ ì§„ë‹¨

  ë¶€ë¶„ë°©ì „ì˜ ì›ì¸ì€ ë‚´ë¶€ ê¸°ê³µì´ë‚˜ ì™¸ë¶€ ëŒê¸° ë“± ë‹¤ì–‘í•œ ì ˆì—°ì²´ ì´ìƒì´ë‹¤. LSì—ì„œëŠ” ì œí’ˆë³„ë¡œ 5~7ê°œì˜ ê²°í•¨ ì›ì¸ì„ êµ¬ë¶„í•˜ê³  ìˆìœ¼ë©°, PDì„¼ì„œë¥¼ í†µí•´ ì–»ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê²°í•¨ì˜ ì›ì¸ì„ ì§„ë‹¨í•œë‹¤. 

*ì˜ˆ) ì´ˆê³ ì•• GISì˜ ë¶€ë¶„ë°©ì „ ì›ì¸ (6ê°€ì§€)*![PD](..\\assets\\images\\mobilenet\\PD.png)



## 2. ê¸°ì¡´ ëª¨ë¸ êµ¬ì¡°

500ì¥ ë¯¸ë§Œì˜ ì ì€ ë°ì´í„°ë¡œ 5~7ê°œ classë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì€ í¬ê¸°ê°€ í´ ê²½ìš° ìì¹« í•™ìŠµì´ ì¶©ë¶„íˆ ì´ë¤„ì§€ì§€ ì•Šì•„ ì„±ëŠ¥ì´ ë‚®ì„ ìˆ˜ ìˆë‹¤. ë‹¨ìˆœí•œ ëª¨ë¸ì„ ì¶©ë¶„íˆ í•™ìŠµí•˜ê¸° ìœ„í•´ ê°€ì¥ ê¸°ë³¸ì ì¸ CNN ëª¨ë¸ì¸ LeNet-5ì˜ êµ¬ì¡°ë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•˜ì˜€ë‹¤. 

* LeNet êµ¬ì¡°![LeNet](..\\assets\\images\\mobilenet\\LeNet.jpeg)

* PD ì§„ë‹¨ ëª¨ë¸ êµ¬ì¡°

```python
class PDModel(nn.Module):
    def __init__(self, classes):
        super(PDModel, self).__init__()

        self.classes = classes

        self.conv = nn.Sequential(
            nn.Conv2d(1, 32, 3, padding=1),  # W: 120 -> 60, H: 60 -> 30
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1),  # W: 60 -> 30, H: 30 -> 15
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),  # W: 30 -> 15, H: 15 -> 7
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(128, 256, 3, padding=1),  # W: 15 -> 7, H: 7 -> 3
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.dense = nn.Sequential(
            nn.Linear(5376, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.Dropout(),
            nn.ReLU(),
            nn.Linear(32, len(self.classes)),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.conv(x)

        x = x.view(-1, 256 * 3 * 7)

        x = self.dense(x)

        return x
```

### ì„±ëŠ¥ ë° í¬ê¸°

Epoch 80, Batch size 64 ê¸°ì¤€

* ì •í™•ë„ : 98.824%
* ëª¨ë¸ í¬ê¸° : 5.54MB



## 3. ê²½ëŸ‰í™” ë°©ë²•

### 3.1. ë„¤íŠ¸ì›Œí¬ ê²½ëŸ‰í™”ì˜ ì¢…ë¥˜

**ë„¤íŠ¸ì›Œí¬ì˜ `ì •í™•ë„`ë¥¼ ë†’ê²Œ ìœ ì§€í•˜ë©° `ì—°ì‚°ì†ë„`ë¥¼ ì˜¬ë¦¬ê±°ë‚˜ `í¬ê¸°`ë¥¼ ì¤„ì´ëŠ” ê²ƒ**

ì°¸ê³ : https://www.youtube.com/watch?v=BhS4EofeY8E&feature=youtu.be
git  : https://github.com/j-marple-dev/model_compression

* **Efficient Architecture Design : íš¨ìœ¨ì´ ë†’ì€ ì•„í‚¤í…ì³ ì„¤ê³„**
* Network Pruning : ì¤‘ìš”ë„ê°€ ë‚®ì€ íŒŒë¼ë¯¸í„° ì œê±°
* Network Quantization : íŒŒë¼ë¯¸í„°ë¥¼ ì¢€ ë” ì‘ì€ í¬ê¸°ì˜ íƒ€ì…ìœ¼ë¡œ í‘œí˜„
* Knowledge Distillation : í•™ìŠµëœ í° ë„¤íŠ¸ì›Œí¬ë¥¼ ì‘ì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµì— ì‚¬ìš©
* Network Compile : ë°”ì´ë„ˆë¦¬ í˜•íƒœë¡œ ë„¤íŠ¸ì›Œí¬ë¥¼ ë³€í™”
* Matrix Decomposition : ë„¤íŠ¸ì›Œí¬ì˜ í–‰ë ¬ ì—°ì‚°ì„ ë” ì‘ì€ í–‰ë ¬ ì—°ì‚°ìœ¼ë¡œ ë³€í™˜
* ...



#### ì™œ MobileNet?

âœ”ï¸ ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?  
     : ë¹ ë¥¸ ì‹œê°„ ì•ˆì— êµ¬í˜„í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.  
    â‡¨ **ìµìˆ™í•œ Convolution ë ˆì´ì–´ì—ì„œ ê³„ì‚° ë°©ë²•ë§Œ ë‹¬ë¼ì§€ëŠ” ê²ƒì´ë‹¤.**  

âœ”ï¸ ê¸°ì¡´ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•  ìˆ˜ ìˆëŠ”ê°€?  
     : Javaë¡œ êµ¬í˜„í•œ ë ˆì´ì–´ì˜ ìˆ˜ì •ì„ ìµœì†Œí™” í•´ì•¼ í•œë‹¤.  
    â‡¨ **Convolution ë ˆì´ì–´ì™€ ë ˆì´ì–´ë¥¼ ì—°ê²°í•˜ëŠ” ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ë©´ ëœë‹¤.**

âœ”ï¸ ì‹¤ì œ íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆëŠ”ê°€?  
      : ë©”ëª¨ë¦¬ì— ë¡œë“œí•œ ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆê°€ ì‘ì•„ì•¼ í•œë‹¤. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë‚´ì—ëŠ” ìˆ˜ë§ì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ë“¤ì´ í•¨ê»˜ ì‹¤í–‰ëœë‹¤.  
        ì „ì²´ì ì¸ ì„±ëŠ¥ì„ ìœ„í•´ì„œë¼ë„ ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆë¥¼ ì‘ê²Œ ë§Œë“¤ì–´ì•¼ í•œë‹¤.  
    â‡¨ **ì—°ì‚° ì†ë„ì™€ ì‹¤ì œ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤.**



### 3.2. MobileNet

  ëª¨ë°”ì¼ì´ë‚˜ ì„ë² ë””ë“œ í™˜ê²½ ë“± ì»´í“¨í„° ì„±ëŠ¥ì´ ì œí•œë˜ê±°ë‚˜ ë°°í„°ë¦¬ í¼í¬ë¨¼ìŠ¤ê°€ ì¤‘ìš”í•œ ê³³ì—ì„œ ì‚¬ìš©ë  ëª©ì ìœ¼ë¡œ ì„¤ê³„ëœ CNNêµ¬ì¡°ì´ë‹¤. `Depthwise Separable Convolution` êµ¬ì¡°ë¥¼ ì´ìš©í•œ **MobileNet V1**ê³¼ ì—¬ê¸°ì— ResNetì˜ `Residual êµ¬ì¡°`ë¥¼ ë”í•˜ì—¬ íŒŒë¼ë¯¸í„° ìˆ˜ì™€ ì—°ì‚°ëŸ‰ì„ ë”ìš± ì¤„ì¸ **Mobile V2**ê°€ ìˆë‹¤. 

#### 3.2.1. MobileNet V1

*MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Application (2017) (https://arxiv.org/pdf/1704.04861.pdf)*



  Mobile V1ì˜ í•µì‹¬ì€ `Depthwise Separable Convolution` ì´ë‹¤. Depthwise Separable Convolutionì´ë€ Depthwise convolutionê³¼ pointwise convolutionì˜ ê²°í•©ì´ë‹¤. ì±„ë„ë‚´ ì—°ì‚°ê³¼ ì±„ë„ê°„ ì—°ì‚°ì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤. Depthwise convolutionì€ ì…ë ¥ ì´ë¯¸ì§€ì˜ ì±„ë„ ê°ê°ì— ê³µí†µëœ 1-channel í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ì‚°í•œë‹¤. ê·¸ ê²°ê³¼, ì…ë ¥ ì±„ë„ ìˆ˜ì™€ ì¶œë ¥ ì±„ë„ ìˆ˜ê°€ ë™ì¼í•˜ë‹¤. Pointwise convolutionì€ depthwise convolutionì˜ ì¶œë ¥ì— ëŒ€í•´ ê° pointë§ˆë‹¤ ì±„ë„ë¼ë¦¬ ì—°ì‚°í•œë‹¤. ì´ë¯¸ì§€ì˜ í¬ê¸°(WxH)ëŠ” ë™ì¼í•˜ë‚˜ ì¶œë ¥ì˜ ì±„ë„ ìˆ˜ë¥¼ ì¡°ì ˆí•  ë•Œ ì‚¬ìš©ëœë‹¤. 

![DepthwiseSeparableConvolution](..\\assets\\images\\mobilenet\\DepthwiseSeparableConvolution.png)



* Depthwise Convolution

  ![DepthwiseConvolution](..\\assets\\images\\mobilenet\\DepthwiseConvolution.png)

  * ì…ë ¥ ì´ë¯¸ì§€ì˜ ê° ì±„ë„ë§ˆë‹¤ spatial featureë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë°©ë²•
  * ê° ì±„ë„ë§ˆë‹¤ í•„í„°ê°€ ì¡´ì¬í•¨ (ì»¤ë„ í¬ê¸° : [ì¶œë ¥ ì±„ë„ ìˆ˜, 1, í•„í„° ë†’ì´, í•„í„° ê°€ë¡œ])
  * ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì±„ë„ ìˆ˜ê°€ ë™ì¼í•¨
  * Grouped convolutionì—ì„œ ê·¸ë£¹ ìˆ˜ë¥¼ ì…ë ¥ ì±„ë„ ìˆ˜ë§Œí¼ ëŠ˜ë¦° ê²ƒê³¼ ë™ì¼í•¨  
: ì…ë ¥ ì±„ë„ì„ ì—¬ëŸ¬ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆˆ í›„ ê³µí†µëœ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ê³  ê°ê° convolutionì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ (ì…ë ¥ ì±„ë„ì„ ë¬¶ìŒìœ¼ë¡œ ë‚˜ëˆ„ì–´ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒ) (ì»¤ë„í¬ê¸°=[ì¶œë ¥ì±„ë„ìˆ˜, ì…ë ¥ì±„ë„ìˆ˜/ê·¸ë£¹ìˆ˜, ë†’ì´, í­])

  ![GroupedConvolution](..\\assets\\images\\mobilenet\\GroupedConvolution.png)

  * ì¼ë°˜ì ì¸ Convolution Layerê³¼ ë¹„êµ
    * ì´ weight íŒŒë¼ë¯¸í„° ìˆ˜ : $`K^2 C_i C_o â†’ K^2 C_i`$
    * ì´ ì—°ì‚°ëŸ‰ : $`K^2 C_i C_o H W â†’ K^2 C_i H W`$

    

* Pointwise Convolution (1X1 Convolution)  
  
  ![PointwiseConvolution](..\\assets\\images\\mobilenet\\PointwiseConvolution.png)

  * 1X1 ê³ ì •ëœ í¬ê¸°ì˜ ì»¤ë„(í•„í„°)ë¥¼ ì‚¬ìš©í•¨
  
  * Channelì— ëŒ€í•œ ì—°ì‚°ë§Œ ìˆ˜í–‰í•˜ì—¬ ì¶œë ¥ ì±„ë„ ìˆ˜ë¥¼ ì¡°ì ˆí•¨
  
  * Dimensional reductionì„ ìœ„í•´ ë§ì´ ì‚¬ìš©í•˜ë©° ì¶”í›„ ì—°ì‚°ëŸ‰ì„ ê°ì†Œì‹œí‚´

  * íŒŒë¼ë¯¸í„° ìˆ˜ì™€ ì—°ì‚°ëŸ‰
  
    * ì´ weight íŒŒë¼ë¯¸í„° ìˆ˜ : $`C_i C_o`$
    * ì´ ì—°ì‚°ëŸ‰ : $`C_i C_o H W`$
  
    
  
* **Depthwise Separable Convolution**  
  
  * Depthwise + Pointwise â†’ Channelê³¼ Spatialí•œ íŠ¹ì§•ì„ ë¶„ë¦¬í•˜ì—¬ ë°”ë¼ë´„
  * íŒŒë¼ë¯¸í„° ìˆ˜ì™€ ì—°ì‚°ëŸ‰
    * ì´ weight íŒŒë¼ë¯¸í„° ìˆ˜ :  $`C_i (K^2 + C_o)`$
    * ì´ ì—°ì‚°ëŸ‰ : $`C_i H W (K^2 + C_o)`$




#### 3.2.2. MobileNet V2

CNNì˜ ë¶„ë¥˜ ë¶€ë¶„ì¸ Linear ë ˆì´ì–´(Fully connected layer)ëŠ” ëª¨ë¸ í¬ê¸°ì— ê°€ì¥ ë§ì€ ì˜í–¥ì„ ë¼ì¹˜ëŠ” ë¶€ë¶„ì´ë‹¤. ì´ì „ Convolution ê²°ê³¼ë¥¼ ëª¨ë‘ 1ì°¨ì›ìœ¼ë¡œ í¼ì³ ì—°ì‚°í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì´ë‹¤. MobileNet V2ì—ì„œëŠ” Linear ë ˆì´ì–´ë¥¼ ê°€ì¥ ë§ˆì§€ë§‰ì— í•œ ë ˆì´ì–´ë§Œ ì‚¬ìš©í•˜ë©° Linear ë ˆì´ì–´ì˜ ì…ë ¥ì„ Convolution ì—°ì‚°ì„ í†µí•´ ìµœì†Œí™” í•œë‹¤. ì´ ë•Œ, ë¶„ë¥˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ResNetì—ì„œ ì‚¬ìš©í•˜ëŠ” residual êµ¬ì¡°ë¥¼ ì´ìš©í•œ Inverted residual block êµ¬ì¡°ë¥¼ ì‚¬ìš©í•œë‹¤. Block ì•ˆì—ì„œ ì±„ë„ ìˆ˜ë¥¼ ì¤„ì´ëŠ” ì¼ë°˜ì ì¸ Residual blockê³¼ ë°˜ëŒ€ë¡œ Inverted residual blockì€ block ë‚´ì—ì„œ ì±„ë„ ìˆ˜ë¥¼ ëŠ˜ë ¤ ì—°ì‚°í•œë‹¤.

![InvertedResidualBlock](..\\assets\\images\\mobilenet\\InvertedResidualBlock.png)

* ì¼ë°˜ì ì¸ Reidual Blck
  
  * Wide â†’ Narrow(Bottleneck) â†’ Wide
  * Skip connectionì„ í†µí•´ ê¸°ì¡´ì— í•™ìŠµí•œ ì •ë³´ë¥¼ ë³´ì¡´í•˜ê³ , ê±°ê¸°ì— ì¶”ê°€ì ìœ¼ë¡œ í•™ìŠµí•¨
    
* Inverted Residual Block
  * ì €ì°¨ì›ì˜ ë°ì´í„°ë¥¼ í™•ì¥ì‹œí‚¤ê³  separable convolutionì„ í†µí•´ ë§ì€ ë°ì´í„°ë¥¼ ë³´ì¡´í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë¨
  * ë§ˆì§€ë§‰ projection ë ˆì´ì–´ëŠ” ì €ì°¨ì› ë°ì´í„°ë¥¼ ì¶œë ¥í•˜ê¸° ë•Œë¬¸ì— activation functionì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì‚¬ìš© ì‹œ ìœ ìš©í•œ ì •ë³´ê°€ ì†ì‹¤ë˜ë¯€ë¡œ)

  

### 3.3. ê²½ëŸ‰í™” ëª¨ë¸

* Convolution Block

  ```python
  def conv(input_channels, output_channels, stride):
      """ì¼ë°˜ì ì¸ Conv ë ˆì´ì–´
  
      Args:
          input_channels: ì…ë ¥ ì±„ë„ ìˆ˜
          output_channels: ì¶œë ¥ ì±„ë„ ìˆ˜
          stride: stride
  
      Return:
          Conv-BatchNorm-LeakyReLU
  
      """
      return nn.Sequential(
          nn.Conv2d(input_channels, output_channels, 3, stride, 1, bias=False),
          nn.BatchNorm2d(output_channels),
          nn.LeakyReLU(0.2, inplace=True),
      )
  ```
  
  * k=3(kernel size)ì¸ Convolution block
  * Normalizationì„ ìœ„í•œ BatchNorm ë ˆì´ì–´ ì¶”ê°€
  * LeakyReLUëŠ” ì„±ëŠ¥ì„ ìœ„í•´ ReLU6ë¡œ ëŒ€ì²´ ê°€ëŠ¥(ë…¼ë¬¸ì—ì„œëŠ” ReLU6ì‚¬ìš©)
  
* Inverted Residual Block (Bottleneck)

  ```python
  class InvertedResidualBlock(nn.Module):
      """Inverted Residual Block í´ë˜ìŠ¤"""
      def __init__(self, input_channels, output_channels, stride, expansion_factor):
          super(InvertedResidualBlock, self).__init__()
  
          self.stride = stride
          self.residual_connect = self.stride == 1 and input_channels == output_channels
  
          hidden_dim = int(input_channels * expansion_factor)
  
          if expansion_factor == 1:
              self.conv = nn.Sequential(
                  # dw
                  nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),
                  nn.BatchNorm2d(hidden_dim),
                  nn.LeakyReLU(0.2, inplace=True),
                  # pw
                  nn.Conv2d(hidden_dim, output_channels, 1, 1, 0, bias=False),
                  nn.BatchNorm2d(output_channels),
              )
          else:
              self.conv = nn.Sequential(
                  # pw
                  nn.Conv2d(input_channels, hidden_dim, 1, 1, 0, bias=False),
                  nn.BatchNorm2d(hidden_dim),
                  nn.LeakyReLU(0.2, inplace=True),
                  # dw
                  nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),
                  nn.BatchNorm2d(hidden_dim),
                  nn.LeakyReLU(0.2, inplace=True),
                  # pw
                  nn.Conv2d(hidden_dim, output_channels, 1, 1, 0, bias=False),
                  nn.BatchNorm2d(output_channels),
              )
  
      def forward(self, x):
          if self.residual_connect:
              return x + self.conv(x)
          else:
              return self.conv(x)
  ```

  * Expansion factorì— ë”°ë¼ ì €ì°¨ì› ì…ë ¥ ë°ì´í„°ì˜ ì±„ë„ì„ í™•ì¥ í›„ í•™ìŠµ
  * expansion_factor = 1ì¸ ê²½ìš°, Separable convolution block ìˆ˜í–‰

* 1x1 Convolution Block (Pointwise Convolution Block)

  ```python
  def conv1x1(input_channels, output_channels):
      """1x1 Conv ë ˆì´ì–´
  
      Args:
          input_channels: ì…ë ¥ ì±„ë„ ìˆ˜
          output_channels: ì¶œë ¥ ì±„ë„ ìˆ˜
  
      Return:
          1x1 Conv-BatchNorm-LeakyReLU
      """
      return nn.Sequential(
          nn.Conv2d(input_channels, output_channels, 1, 1, 0, bias=False),
          nn.BatchNorm2d(output_channels),
          nn.LeakyReLU(0.2, inplace=True),
      )
  ```

  * k=1ì¸ Convolution block
  * Output channel ìˆ˜ë¥¼ ì¡°ì ˆí•˜ê¸° ìœ„í•´ ì‚¬ìš©  

  
* Main Model

  ```python
  class PDLightModel(nn.Module):
      """PD ëª¨ë¸ ê²½ëŸ‰í™” ë²„ì „(MobileNet Ver.2 ì ìš©)"""
      def __init__(self, classes):
          super(PDLightModel, self).__init__()
  
          self.classes = classes
  
          self.layers = [
              # conv 3x3
              conv(1, 32, 2),
              # n = 1
              InvertedResidualBlock(32, 16, 1, 1),
              # n = 2
              InvertedResidualBlock(16, 24, 2, 6),
              InvertedResidualBlock(24, 24, 1, 6),
              # n = 3
              InvertedResidualBlock(24, 32, 2, 6),
              InvertedResidualBlock(32, 32, 1, 6),
              InvertedResidualBlock(32, 32, 1, 6),
              # n = 3
              InvertedResidualBlock(32, 64, 2, 6),
              InvertedResidualBlock(64, 64, 1, 6),
              InvertedResidualBlock(64, 64, 1, 6),
              # conv 1x1
              conv1x1(64, 256)
          ]
          # Feature Extractor
          self.extractor = nn.Sequential(*self.layers)
          self.classifier = nn.Sequential(
              nn.Linear(256, len(self.classes)),
              nn.Softmax()
          )
  
      def forward(self, x):
          x = self.extractor(x)
          x = x.mean(3).mean(2)
          x = self.classifier(x)
          return x
  ```

  * ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°

    |    Input     |  Operator   | expand_ratio | output_channels | stride |
    | :----------: | :---------: | :----------: | :-------------: | :----: |
    | 1 x 60 x 120 |    conv     |      -       |       32        |   2    |
    | 32 x 30x 60  | bottleneck  |      1       |       16        |   1    |
    | 16 x 30 x 60 | bottleneck  |      6       |       24        |   2    |
    | 24 x 15 x 30 | bottleneck  |      6       |       24        |   1    |
    | 24 x 15 x 30 | bottleneck  |      6       |       32        |   2    |
    | 32 x 7 x 15  | bottleneck  |      6       |       32        |   1    |
    | 32 x 7 x 15  | bottleneck  |      6       |       32        |   1    |
    | 32 x 7 x 15  | bottleneck  |      6       |       64        |   2    |
    |  61 x 3 x 7  | bottleneck  |      6       |       64        |   1    |
    |  64 x 3 x 7  | bottleneck  |      6       |       64        |   1    |
    |  64 x 3 x 7  |  conv 1x1   |      -       |       256       |   1    |
    | 256 x 3 x 7  | avgpool 3x7 |      -       |        1        |   1    |
    |     256      |   linear    |      -       |  len(classes)   |   -    |
    | len(classes) |   softmax   |      -       |  len(classes)   |   -    |

  * ë¶„ë¥˜ê¸°ì— Linear layer(Fully connected layer) 1ê°œ + Softmax í•¨ìˆ˜ë§Œ ì‚¬ìš©  
  * Linear layer ì „ì— Average pooling layerë¥¼ ë°°ì¹˜í•¨ìœ¼ë¡œì¨ ì…ë ¥ ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ì¤„ì„

  

### ì„±ëŠ¥ ë° í¬ê¸°

Epochs : 36 (learning rate=0.0001) + 17(lr=0.00001)
Batch size : 4

* **ì •í™•ë„ : 92.77% (6% ê°ì†Œ)** (ë‹¨, ê²½ëŸ‰í™” ëª¨ë¸ íŠœë‹ ì‹œ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥)
* **ëª¨ë¸ í¬ê¸°(íŒŒì¼ í¬ê¸°) : 1.62MB (ê¸°ì¡´ í¬ê¸°ì˜ 29.2%)**

